{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-15T22:40:00.571303Z","iopub.execute_input":"2022-08-15T22:40:00.571872Z","iopub.status.idle":"2022-08-15T22:40:00.604318Z","shell.execute_reply.started":"2022-08-15T22:40:00.571764Z","shell.execute_reply":"2022-08-15T22:40:00.603283Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(os.path.join(dirname, 'goodreads_train.csv'))\ntest_csv = pd.read_csv(os.path.join(dirname, 'goodreads_test.csv'))\n\ntrain_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:00.605945Z","iopub.execute_input":"2022-08-15T22:40:00.606575Z","iopub.status.idle":"2022-08-15T22:40:35.481475Z","shell.execute_reply.started":"2022-08-15T22:40:00.606542Z","shell.execute_reply":"2022-08-15T22:40:35.479996Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.483652Z","iopub.execute_input":"2022-08-15T22:40:35.484564Z","iopub.status.idle":"2022-08-15T22:40:35.502468Z","shell.execute_reply.started":"2022-08-15T22:40:35.484445Z","shell.execute_reply":"2022-08-15T22:40:35.500336Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train_csv)\ntrain = reduce_mem_usage(test_csv)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.506896Z","iopub.execute_input":"2022-08-15T22:40:35.507398Z","iopub.status.idle":"2022-08-15T22:40:35.586855Z","shell.execute_reply.started":"2022-08-15T22:40:35.507361Z","shell.execute_reply":"2022-08-15T22:40:35.585222Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# First impressions\nWe have a dataframe with 900k reviews about several books. From these, we may be able to predict the review range in the test dataframe (from 1 to 5).","metadata":{}},{"cell_type":"code","source":"train_csv = train_csv[:30000]\nprint('n of rows : '+str(train_csv.shape[0])+' n of columns: '+str(train_csv.shape[1]))\ntrain_csv.info()\ntrain_csv.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.588631Z","iopub.execute_input":"2022-08-15T22:40:35.588951Z","iopub.status.idle":"2022-08-15T22:40:35.666684Z","shell.execute_reply.started":"2022-08-15T22:40:35.588919Z","shell.execute_reply":"2022-08-15T22:40:35.665671Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Users behavior\nWe need to check if there are users that posts multiple reviews and how much of those. From these users, we can discover if there is any pattern in they reviews - some users may post negative reviews, but others seems to have a nice impression of the books in general.\n\nThe conclusion is that the top 10 users in number of reviews has 990+ reviews each.","metadata":{}},{"cell_type":"code","source":"print(train_csv['user_id'].value_counts().head(10))\nprint(len(train_csv['user_id'].value_counts()))\nprint('total users with less than 10 reviews: '+ str(sum((train_csv['user_id'].value_counts()<10))))\nprint('total users with less than 50 reviews: '+ str(sum(train_csv['user_id'].value_counts()<50)))\nprint('total users with less than 100 reviews: '+ str(sum(train_csv['user_id'].value_counts()<100)))\nprint('total users with less than 500 reviews: '+ str(sum(train_csv['user_id'].value_counts()<500)))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.668486Z","iopub.execute_input":"2022-08-15T22:40:35.668863Z","iopub.status.idle":"2022-08-15T22:40:35.695557Z","shell.execute_reply.started":"2022-08-15T22:40:35.668805Z","shell.execute_reply":"2022-08-15T22:40:35.693908Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmean_rating_by_user = train_csv.groupby(['user_id'])['rating'].mean()\n\nmean_rating_by_user.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.697363Z","iopub.execute_input":"2022-08-15T22:40:35.697701Z","iopub.status.idle":"2022-08-15T22:40:35.717211Z","shell.execute_reply.started":"2022-08-15T22:40:35.697667Z","shell.execute_reply":"2022-08-15T22:40:35.715889Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# What does the best reviews has in common?","metadata":{}},{"cell_type":"code","source":"print('The mean of all reviews is a rating of: '+str(train_csv['rating'].mean()))\nrating_counts = train_csv['rating'].value_counts()\n\nprint(rating_counts.keys())\n\nfig = plt.figure(figsize = (10, 5))\nplt.bar(rating_counts.keys(), rating_counts, color ='maroon',\n        width = 0.4)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.718514Z","iopub.execute_input":"2022-08-15T22:40:35.719957Z","iopub.status.idle":"2022-08-15T22:40:35.996320Z","shell.execute_reply.started":"2022-08-15T22:40:35.719916Z","shell.execute_reply":"2022-08-15T22:40:35.994908Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"votes_by_rating = train_csv.groupby('rating')['n_votes'].sum()\nprint(votes_by_rating)\n\nfig = plt.figure(figsize = (10, 5))\nplt.bar(votes_by_rating.keys(), votes_by_rating, color ='maroon',\n        width = 0.4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:35.997627Z","iopub.execute_input":"2022-08-15T22:40:35.998411Z","iopub.status.idle":"2022-08-15T22:40:36.243052Z","shell.execute_reply.started":"2022-08-15T22:40:35.998372Z","shell.execute_reply":"2022-08-15T22:40:36.241480Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# How users treat a same book?","metadata":{}},{"cell_type":"code","source":"numbers_by_book = train_csv.groupby('book_id')['rating'].sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:36.248047Z","iopub.execute_input":"2022-08-15T22:40:36.249019Z","iopub.status.idle":"2022-08-15T22:40:36.262530Z","shell.execute_reply.started":"2022-08-15T22:40:36.248952Z","shell.execute_reply":"2022-08-15T22:40:36.260899Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Treating the reviews text","metadata":{}},{"cell_type":"code","source":"review_text_by_word = { i : el.split() for i, el in enumerate(train_csv['review_text']) }\nreview_text_by_word_test = { i : el.split() for i, el in enumerate(test_csv['review_text']) }\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:36.264728Z","iopub.execute_input":"2022-08-15T22:40:36.265078Z","iopub.status.idle":"2022-08-15T22:40:55.155566Z","shell.execute_reply.started":"2022-08-15T22:40:36.265044Z","shell.execute_reply":"2022-08-15T22:40:55.153939Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_bow(el):\n    \n    filtered_bow = clean_bow(el)\n    bow_dict = dict.fromkeys(filtered_bow)\n    \n    for word in filtered_bow:\n        bow_dict[word] = filtered_bow.count(word)\n    \n    df_bow = pd.DataFrame({'Word': list(bow_dict.keys()), 'Frequency': list(bow_dict.values())})\n    return df_bow.sort_values(by='Frequency', ascending=False)\n\n\ndef clean_bow(el):\n    new_list = []\n    \n    bag_of_garbage = ['-', 'a', 'about', 'and', 'as', 'at', 'book', 'by', 'for', 'i', 'in', \n                      'is', 'it', 'of', 'the', 'that', 'this', 'to', 'was']\n    \n    for word in el:\n        word = word.lower()\n        if not word in bag_of_garbage:\n            new_list.append(word)\n    \n    return new_list\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:55.157109Z","iopub.execute_input":"2022-08-15T22:40:55.157479Z","iopub.status.idle":"2022-08-15T22:40:55.168224Z","shell.execute_reply.started":"2022-08-15T22:40:55.157445Z","shell.execute_reply":"2022-08-15T22:40:55.166551Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### Cleaning data from garbage words","metadata":{}},{"cell_type":"code","source":"for i, text in enumerate(review_text_by_word.values()):\n    review_text_by_word[i] = clean_bow(text)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:55.169969Z","iopub.execute_input":"2022-08-15T22:40:55.170296Z","iopub.status.idle":"2022-08-15T22:40:57.699511Z","shell.execute_reply.started":"2022-08-15T22:40:55.170263Z","shell.execute_reply":"2022-08-15T22:40:57.698147Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#check if there is good words in it\n\ndef get_positive_bow(el):\n    \n    positive_bow = ['awesome', 'beautiful', 'enjoy', 'enjoyed', 'enjoying', 'fascinating', \n                    'fantastic', 'favorite', 'favorites',\n                    'gold', 'good', 'great', 'happy', 'interesting', \n                    'like', 'love', 'loved', 'nice', 'recommended']\n    negative_bow = ['1', '2', 'annoying', 'bad', 'bored', 'boring', \"couldn't\", 'disappoint', 'disappointed', 'disappointment',\n                    'horible', 'inaccurate', 'ruin', 'ruined', 'shit', 'stopped', 'sucks', 'terrible', 'tried', \"wasn't\"]\n    negative_bow_to_connect = [\"didn't\", \"don't\", 'no', 'not']\n    negative_bow_connected = ['care', 'connect', 'finish', 'interest', 'much', 'need', 'sure', 'work', 'rating']\n    positive_counter = 0\n    negative_counter = 0\n    text_classification = 1  ##### 0 = negative, 1 = positive. as most part of the \n                             ####  books are well rated, I set positive as default\n    \n    for i, word in enumerate(el):\n        if word.lower() in negative_bow_to_connect: #if there is a 'not' or other negative word, check if the next word is a positive one. If true, the negative counter recieves a high number of points\n            if el[i] != el[-1] and el[i+1].lower() in positive_bow:\n                negative_counter+=10\n        elif word.lower() in positive_bow:\n            positive_counter+=1\n        elif word.lower() in negative_bow:\n            negative_counter +=3\n    \n    if negative_counter > positive_counter:\n        text_classification = 0\n    \n    return text_classification\n\ntrain_csv['text_category'] = 0\ntest_csv['text_category'] = 0\n\nfor i, el in enumerate(review_text_by_word.values()):\n    train_csv['text_category'][i] = get_positive_bow(el)\n\n\nfor i, el in enumerate(review_text_by_word_test.values()):\n    test_csv['text_category'][i] = get_positive_bow(el)\n    \ntrain_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:40:57.701096Z","iopub.execute_input":"2022-08-15T22:40:57.701421Z","iopub.status.idle":"2022-08-15T22:45:42.561535Z","shell.execute_reply.started":"2022-08-15T22:40:57.701387Z","shell.execute_reply":"2022-08-15T22:45:42.559795Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import collections\n#train_csv[['rating', 'text_category']][700:710]\n#train_csv['review_text'][702]\n\n#print(train_csv.loc[train_csv['rating']==1][['review_text', 'text_category']])\n#train_csv['review_text'][801]\n\nbag_of_garbage = ['-', 'a', 'at', 'about', 'and', 'as', 'at', 'book', 'but', 'by', 'for',\n                  'have', 'her', 'i', 'if', 'in', 'is', 'it', 'just', 'my', 'of', 'she', \n                  'so', 'the', 'that', 'this', 'to', 'was', 'with', 'you']\n\nzero_string = ' '.join(list(train_csv.loc[train_csv['rating']==0]['review_text'])).lower()\nzero_bow = zero_string.split()\n\n\nfor word in bag_of_garbage:\n    new_bow = filter(lambda a: a != word, zero_bow)\n    zero_bow = list(new_bow)\n\n\n#print(zero_bow)\n#print(collections.Counter(zero_bow))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:45:42.563241Z","iopub.execute_input":"2022-08-15T22:45:42.563655Z","iopub.status.idle":"2022-08-15T22:45:42.767011Z","shell.execute_reply.started":"2022-08-15T22:45:42.563619Z","shell.execute_reply":"2022-08-15T22:45:42.765779Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"count_not = 0\nnew_bow = []\n\nfor i, word in enumerate(zero_bow):\n    if word == \"didn't\":\n        count_not+=1\n        new_bow.append(zero_bow[i+1])\n\nprint(count_not)\nprint(collections.Counter(new_bow))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:45:42.768897Z","iopub.execute_input":"2022-08-15T22:45:42.769720Z","iopub.status.idle":"2022-08-15T22:45:42.784895Z","shell.execute_reply.started":"2022-08-15T22:45:42.769671Z","shell.execute_reply":"2022-08-15T22:45:42.783339Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Is categories really effective?\nCheck if the category of bad (0) or good (1) reviews are beeing effectivelly working. ","metadata":{}},{"cell_type":"code","source":"rating_by_category = train_csv.groupby('text_category')\nprint(sum(rating_by_category['rating'].value_counts()))\nprint(rating_by_category['rating'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:45:42.787413Z","iopub.execute_input":"2022-08-15T22:45:42.788181Z","iopub.status.idle":"2022-08-15T22:45:42.806567Z","shell.execute_reply.started":"2022-08-15T22:45:42.788142Z","shell.execute_reply":"2022-08-15T22:45:42.805079Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Initial tests to the model","metadata":{}},{"cell_type":"code","source":"#Adjust categorical string values to integer values.\n## user_id\nuser_id_dict =  { el : i for i, el in enumerate(train_csv['user_id']) }\nuser_id_dict_invert =  { i : el for i, el in enumerate(user_id_dict.keys()) }\n#train_csv.replace({'user_id': user_id_dict}, inplace=True)\n#test_csv.replace({'user_id': user_id_dict}, inplace=True)\ntrain_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:45:42.808527Z","iopub.execute_input":"2022-08-15T22:45:42.808927Z","iopub.status.idle":"2022-08-15T22:45:42.836353Z","shell.execute_reply.started":"2022-08-15T22:45:42.808893Z","shell.execute_reply":"2022-08-15T22:45:42.835387Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_csv[['year_of_review', 'month_of_review']] = 0\ntest_csv[['year_of_review', 'month_of_review']] = 0\n\nmonths_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, \n               'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n\nfor i, el in enumerate(train_csv['date_added']):\n    train_csv['year_of_review'][i] = train_csv['date_added'][i][-4:]\n    month = train_csv['date_added'][i][4:7]\n    train_csv['month_of_review'][i] = months_dict[month]\n\n\nfor i, el in enumerate(test_csv['date_added']):\n    test_csv['year_of_review'][i] = test_csv['date_added'][i][-4:]\n    month = test_csv['date_added'][i][4:7]\n    test_csv['month_of_review'][i] = months_dict[month]\n    \ntrain_csv['month_of_review'].head()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:45:42.837916Z","iopub.execute_input":"2022-08-15T22:45:42.838557Z","iopub.status.idle":"2022-08-15T22:52:03.437689Z","shell.execute_reply.started":"2022-08-15T22:45:42.838524Z","shell.execute_reply":"2022-08-15T22:52:03.436051Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n#train_csv.replace({'month_of_review': user_id_dict}, inplace=True)\n#train_csv['month_of_review'].head(20)\n\nmonth = 'Sep'\nprint(months_dict[month])","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:52:03.440097Z","iopub.execute_input":"2022-08-15T22:52:03.440673Z","iopub.status.idle":"2022-08-15T22:52:03.448856Z","shell.execute_reply.started":"2022-08-15T22:52:03.440607Z","shell.execute_reply":"2022-08-15T22:52:03.447388Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n\ny = train_csv['rating']\nX = train_csv[['book_id', 'text_category']]\nX = train_csv[['book_id', 'n_votes', 'book_id', 'n_comments', 'text_category', 'year_of_review', 'month_of_review']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n\nmodel = LinearSVC()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, prediction) * 100\nprint(f'{accuracy}% accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:52:03.450887Z","iopub.execute_input":"2022-08-15T22:52:03.451531Z","iopub.status.idle":"2022-08-15T22:52:16.874995Z","shell.execute_reply.started":"2022-08-15T22:52:03.451480Z","shell.execute_reply":"2022-08-15T22:52:16.872804Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_csv['rating']\n\n#features = ['n_votes', 'book_id', 'n_comments', 'text_category', 'year_of_review', 'month_of_review']\nfeatures = [,'text_category']\n\nX = pd.get_dummies(train_csv[features])\nX_test = pd.get_dummies(test_csv[features])\n\npd.get_dummies(train_csv[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\n\npredictions = model.predict(X_test)\noutput = pd.DataFrame({'review_id': test_csv.review_id, 'rating': predictions})\noutput.to_csv('submission.csv', index=False)\nprint('Your submission was successfully saved')","metadata":{"execution":{"iopub.status.busy":"2022-08-15T22:52:16.877756Z","iopub.execute_input":"2022-08-15T22:52:16.878413Z","iopub.status.idle":"2022-08-15T22:52:16.903906Z","shell.execute_reply.started":"2022-08-15T22:52:16.878345Z","shell.execute_reply":"2022-08-15T22:52:16.901513Z"},"trusted":true},"execution_count":22,"outputs":[]}]}